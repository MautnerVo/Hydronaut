{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-22T21:10:59.836911Z",
     "start_time": "2025-08-22T21:10:49.952868Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T21:10:59.850624Z",
     "start_time": "2025-08-22T21:10:59.848169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = r\"Y:\\Datasets\\Fyzio\"\n",
    "exercise = \"Wide squat\"\n"
   ],
   "id": "d72b3714ae6c6950",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T21:14:17.464266Z",
     "start_time": "2025-08-22T21:10:59.861870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(path,\"X_train\",exercise + \".pkl\"),\"rb\") as f:\n",
    "    x = np.array(pickle.load(f))\n",
    "    print(x.shape)"
   ],
   "id": "7ad0981892027cc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20551, 200, 20)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T21:14:23.541656Z",
     "start_time": "2025-08-22T21:14:18.050873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(path,\"Y_train\",exercise + \".pkl\"),\"rb\") as f:\n",
    "    y = np.array(pickle.load(f))\n",
    "    print(y.shape)\n"
   ],
   "id": "cba7e8ccf8dffd95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20551, 1)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T21:14:25.463908Z",
     "start_time": "2025-08-22T21:14:23.600054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "x_norm = np.zeros_like(x)\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "for ch in range(x.shape[1]):\n",
    "    mean = x[:, ch, :].mean()\n",
    "    std = x[:, ch, :].std()\n",
    "    x_norm[:, ch, :] = (x[:, ch, :] - mean) / std\n",
    "    means.append(mean)\n",
    "    stds.append(std)\n",
    "\n",
    "# y_min = y.min(axis=0, keepdims=True)\n",
    "# y_max = y.max(axis=0, keepdims=True)\n",
    "# y_norm = (y - y_min) / (y_max - y_min)\n",
    "y_norm = y/100"
   ],
   "id": "e5312fc03eab5592",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T21:14:25.593898Z",
     "start_time": "2025-08-22T21:14:25.495435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_norm_t = torch.from_numpy(y_norm).float()[:,0]\n",
    "\n",
    "x_norm_t = torch.from_numpy(x_norm).float()\n",
    "x_norm_t = x_norm_t.permute(0,2,1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_norm_t,y_norm_t,test_size=0.3,random_state=42)\n",
    "print(y_train)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ],
   "id": "f91d0eef4b65fedf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8793, 0.5044, 0.0193,  ..., 0.8471, 0.7234, 0.6378])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T21:14:25.653933Z",
     "start_time": "2025-08-22T21:14:25.643453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cnn1 = 64\n",
    "cnn2 = 128\n",
    "cnn3 = 128\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels,seq_len):\n",
    "        super(Net,self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(in_channels, cnn1, kernel_size=3, padding=1)\n",
    "        self.normalization1=nn.BatchNorm1d(cnn1)\n",
    "        self.pool1= nn.MaxPool1d(2)\n",
    "        self.cnn2 = nn.Conv1d(cnn1, cnn2, kernel_size=3, padding=1)\n",
    "        self.normalization2=nn.BatchNorm1d(cnn2)\n",
    "        self.pool2= nn.MaxPool1d(2)\n",
    "        self.cnn3 = nn.Conv1d(cnn2, cnn3, kernel_size=3, padding=1)\n",
    "        self.normalization3=nn.BatchNorm1d(cnn3)\n",
    "        self.pool3= nn.MaxPool1d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, seq_len)\n",
    "            out = self.pool1(F.relu(self.cnn1(dummy)))\n",
    "            out = self.pool2(F.relu(self.cnn2(out)))\n",
    "            out = self.pool3(F.relu(self.cnn3(out)))\n",
    "            flat_dim = out.view(1, -1).size(1)\n",
    "\n",
    "\n",
    "        self.snn1 = nn.Linear(flat_dim, 64)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.snn2 = nn.Linear(64, 8)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.snn3 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.normalization1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.normalization2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.cnn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.normalization3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.snn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.snn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        out = self.snn3(x)\n",
    "        return out\n",
    "\n",
    "# in_channels = x_train.shape[1]\n",
    "# seq_len = x_train.shape[2]\n",
    "#\n",
    "# out_features = 1\n",
    "#\n",
    "# net = Net(in_channels,seq_len).to(device)\n",
    "# params = list(net.parameters())\n",
    "# print(len(params))\n",
    "# print(params[0].size())\n"
   ],
   "id": "4fc1ece83b23cc6a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T21:14:25.668513Z",
     "start_time": "2025-08-22T21:14:25.663082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "#\n",
    "# train_dataset = TensorDataset(x_train, y_train)\n",
    "# val_dataset = TensorDataset(x_test, y_test)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "ce2ec25e33b7cd4e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-22T21:27:53.469268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X = x_norm_t.cpu().numpy()\n",
    "Y = y_norm_t.cpu().numpy()\n",
    "\n",
    "in_channels = x_train.shape[1]\n",
    "seq_len = x_train.shape[2]\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    Y_train, Y_val = Y[train_idx], Y[val_idx]\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    Y_val_tensor = torch.tensor(Y_val, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    net = Net(in_channels, seq_len).to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                val_outputs = net(batch_X)\n",
    "                loss = criterion(val_outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = net(X_val_tensor.to(device)).numpy().flatten()\n",
    "        y_true = Y_val_tensor.numpy().flatten()\n",
    "\n",
    "    mse = mean_squared_error(y_true, preds)\n",
    "    r2 = r2_score(y_true, preds)\n",
    "    print(f\"Fold {fold+1} - MSE: {mse:.4f}, R²: {r2:.4f}\\n\")\n",
    "\n",
    "    fold_results.append((y_true, preds))\n",
    "mse_l = []\n",
    "r2_l = []\n",
    "\n",
    "for y_true, preds in fold_results:\n",
    "    mse_l.append(mean_squared_error(y_true, preds))\n",
    "    r2_l.append(r2_score(y_true, preds))\n",
    "\n",
    "print(np.mean(mse_l))\n",
    "print(np.mean(r2_l))"
   ],
   "id": "1049bb0ea9bb07fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mse_l = []\n",
    "r2_l = []\n",
    "for y_true, preds in fold_results:\n",
    "    mse_l.append(mean_squared_error(y_true, preds))\n",
    "    r2_l.append(r2_score(y_true, preds))\n",
    "\n",
    "print(np.mean(mse_l))\n",
    "print(np.mean(r2_l))"
   ],
   "id": "86ae73971c710998",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Training\n",
    "\n",
    "# import torch.optim as optim\n",
    "# from sklearn.model_selection import KFold\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=5e-4)\n",
    "#\n",
    "#\n",
    "# epochs = 100\n",
    "# for epoch in range(epochs):\n",
    "#     net.train()\n",
    "#     train_loss = 0.0\n",
    "#     for batch_X, batch_y in train_loader:\n",
    "#         batch_X = batch_X.to(device)\n",
    "#         batch_y = batch_y.to(device).float().unsqueeze(1)\n",
    "#\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = net(batch_X)\n",
    "#         loss = criterion(outputs, batch_y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#         train_loss += loss.item()\n",
    "#\n",
    "#     train_loss /= len(train_loader)\n",
    "#\n",
    "#     net.eval()\n",
    "#     val_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for batch_X, batch_y in val_loader:\n",
    "#             batch_X = batch_X.to(device)\n",
    "#             batch_y = batch_y.to(device).float().unsqueeze(1)\n",
    "#             val_outputs = net(batch_X)\n",
    "#             loss = criterion(val_outputs, batch_y)\n",
    "#             val_loss += loss.item()\n",
    "#\n",
    "#     val_loss /= len(val_loader)\n",
    "#\n",
    "#     print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\\n\")\n"
   ],
   "id": "12e79aea9f4c6047",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "89bd161b3fb95ad4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_train[10])\n",
    "plt.show()"
   ],
   "id": "228d4fa91bf2d98e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = net(x_test.to(device))\n",
    "\n",
    "preds = outputs.cpu().numpy().flatten()\n",
    "y_true = y_test.cpu().numpy().flatten()\n",
    "\n",
    "plt.scatter(range(len(y_true)), y_true, label=\"True\", color=\"blue\")\n",
    "plt.scatter(range(len(preds)), preds, label=\"Predicted\", color=\"red\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "2a188b474218c1f8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
